{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c1c898",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from wordcloud import WordCloud\n",
    "plt.rcParams['figure.dpi'] = 80\n",
    "plt.rcParams['savefig.dpi'] = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174361a8",
   "metadata": {},
   "source": [
    "## Lista de keywords de um determinado ano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62fcb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"keywords_all_year.json\")\n",
    "all_text_year = list(json.load(f))\n",
    "keywords_year = {}\n",
    "text_quant_year = {}\n",
    "\n",
    "for a in all_text_year:\n",
    "    if a['year'] not in keywords_year.keys():\n",
    "        keywords_year[a['year']] = a['keywords']\n",
    "        text_quant_year[a['year']] = 1\n",
    "    elif  a['year'] in keywords_year.keys():\n",
    "        text_quant_year[a['year']] += 1\n",
    "        for b in a['keywords']:\n",
    "            keywords_year[a['year']].append(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bcf920",
   "metadata": {},
   "source": [
    "## Lista de keywords de acordo com ano e tipo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2877ec07",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"keywords_all_year.json\")\n",
    "all_text_year = list(json.load(f))\n",
    "keywords_yearNtype = {}\n",
    "text_quant_yearNtype = {}\n",
    "\n",
    "for c in all_text_year:\n",
    "    conj_value = c['year'] + '_' + c['text_type']\n",
    "    if conj_value not in keywords_yearNtype.keys():\n",
    "        keywords_yearNtype[conj_value] = c['keywords']\n",
    "        text_quant_yearNtype[conj_value] = 1\n",
    "    elif  conj_value in keywords_yearNtype.keys():\n",
    "        text_quant_yearNtype[conj_value] += 1\n",
    "        for d in c['keywords']:\n",
    "            keywords_yearNtype[conj_value].append(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb7aa55",
   "metadata": {},
   "source": [
    "## Lista de keywords de acordo com tipo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67597dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"keywords_all_year.json\")\n",
    "all_text_year = list(json.load(f))\n",
    "keywords_type = {}\n",
    "text_quant_type = {}\n",
    "\n",
    "for e in all_text_year:\n",
    "    if e['text_type'] not in keywords_type.keys():\n",
    "        keywords_type[e['text_type']] = e['keywords']\n",
    "        text_quant_type[e['text_type']] = 1\n",
    "    elif  e['text_type'] in keywords_type.keys():\n",
    "        text_quant_type[e['text_type']] += 1\n",
    "        for f in e['keywords']:\n",
    "            keywords_type[e['text_type']].append(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd61838",
   "metadata": {},
   "source": [
    "## Grafico de linhas de plano de negÃ³cio e monografia por ano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43353d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = {'year': ['2021','2020','2019','2018','2017','2016'], 'plano': [], 'monografia': []}\n",
    "valor1 = 0\n",
    "valor2 = 0\n",
    "\n",
    "for i in text_quant_yearNtype:\n",
    "    valor1 = text_quant_yearNtype[i]\n",
    "    for j in text_quant_yearNtype:\n",
    "        if j[j.find('_')+1:] != i[i.find('_')+1:] and j[:j.find('_')] == i[:i.find('_')]:\n",
    "            valor2 = text_quant_yearNtype[j]\n",
    "    data1[i[i.find('_')+1:]].append(valor1/(valor1+valor2))\n",
    "    \n",
    "data1['year'].reverse()\n",
    "data1['plano'].reverse()\n",
    "data1['monografia'].reverse()\n",
    "\n",
    "data_preproc = pd.DataFrame(data1)\n",
    "fig = sns.lineplot(x='year', y='value', hue='variable', \n",
    "             data=pd.melt(data_preproc, ['year']), marker=\"o\")\n",
    "\n",
    "fig.set(xlabel='Ano', ylabel='Percentual', ylim=(0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7218aed",
   "metadata": {},
   "source": [
    "## Grafico de quantidade de TCCs por ano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b501567c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = {'year': ['2021','2020','2019','2018','2017','2016'], 'tcc': []}\n",
    "valor1 = 0\n",
    "valor2 = 0\n",
    "\n",
    "for j in data2['year']:\n",
    "    data2['tcc'].append(text_quant_year[j])\n",
    "    \n",
    "data2['year'].reverse()\n",
    "data2['tcc'].reverse()\n",
    "    \n",
    "data_preproc = pd.DataFrame(data2)\n",
    "sns.barplot(x='year', y='value', hue='variable', \n",
    "             data=pd.melt(data_preproc, ['year']))\n",
    "\n",
    "print(data2['tcc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a6f388",
   "metadata": {},
   "source": [
    "## Nuvem de palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372ffb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ano = '2021' #Definir ano\n",
    "text =  \" \".join(keywords_year[ano])\n",
    "text = text.replace(\" p \", \" \")\n",
    "# Arredondar\n",
    "x, y = np.ogrid[:300, :300]\n",
    "mask = (x - 150) ** 2 + (y - 150) ** 2 > 130 ** 2\n",
    "mask = 255 * mask.astype(int)\n",
    "\n",
    "wordcloud = WordCloud().generate(text)\n",
    "\n",
    "wordcloud = WordCloud(mask=mask, background_color=\"white\",max_words=len(keywords_year[ano]),max_font_size=40, relative_scaling=.5).generate(text)\n",
    "plt.figure()\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2eaa98",
   "metadata": {},
   "source": [
    "## Principais palavras de cada ano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35fdd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "blocked_words = ['unk', '<', '>']\n",
    "word_count_year = {}\n",
    "for i in keywords_year:\n",
    "    word_count_year[i] = {}\n",
    "    for j in keywords_year[i]:\n",
    "        if j not in word_count_year[i] and j not in blocked_words:\n",
    "            word_count_year[i][j] = 1\n",
    "        elif j in word_count_year[i] and j not in blocked_words:\n",
    "            word_count_year[i][j] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89509023",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_used_word_year = {}\n",
    "for k in keywords_year:\n",
    "    word_count_year[k] = dict(sorted(word_count_year[k].items(), key=lambda item: item[1], reverse=True))\n",
    "    most_used_word_year[k] = [list(word_count_year[k].keys())[0], list(word_count_year[k].values())[0]/text_quant_year[k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26254f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data4 = {'year': ['2021','2020','2019','2018','2017','2016'], 'most used word': [], 'percentage': []}\n",
    "\n",
    "for j in data4['year']:\n",
    "    data4['most used word'].append(most_used_word_year[j][0])\n",
    "    data4['percentage'].append(most_used_word_year[j][1])\n",
    "    \n",
    "data4['year'].reverse()\n",
    "data4['most used word'].reverse()\n",
    "data4['percentage'].reverse()\n",
    "\n",
    "palette = ['r']\n",
    "    \n",
    "df = pd.DataFrame(data4)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94ea2be",
   "metadata": {},
   "source": [
    "## Principais palavras de cada ano excluindo a palavra empresa e ano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a47ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "blocked_words = ['unk', '<', '>', 'empresa', 'ano']\n",
    "word_count_year2 = {}\n",
    "for i in keywords_year:\n",
    "    word_count_year2[i] = {}\n",
    "    for j in keywords_year[i]:\n",
    "        if j not in word_count_year2[i] and j not in blocked_words:\n",
    "            word_count_year2[i][j] = 1\n",
    "        elif j in word_count_year2[i] and j not in blocked_words:\n",
    "            word_count_year2[i][j] += 1\n",
    "\n",
    "most_used_word_year2 = {}\n",
    "for k in keywords_year:\n",
    "    word_count_year2[k] = dict(sorted(word_count_year2[k].items(), key=lambda item: item[1], reverse=True))\n",
    "    most_used_word_year2[k] = [list(word_count_year2[k].keys())[0], list(word_count_year2[k].values())[0]/text_quant_year[k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfebcb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "data6 = {'year': ['2021','2020','2019','2018','2017','2016'], 'most used word': [], 'percentage': []}\n",
    "\n",
    "for j in most_used_word_year2:\n",
    "    data6['most used word'].append(most_used_word_year2[j][0])\n",
    "    data6['percentage'].append(most_used_word_year2[j][1])\n",
    "    \n",
    "data6['year'].reverse()\n",
    "data6['most used word'].reverse()\n",
    "data6['percentage'].reverse()\n",
    "\n",
    "palette = ['r']\n",
    "    \n",
    "df2 = pd.DataFrame(data6)\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c075b7b3",
   "metadata": {},
   "source": [
    "## Principais palavras de cada ano por tipo de TCC excluindo a palavra 'empresa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df90f1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "blocked_words = ['unk', '<', '>', 'ano', 'empresa', 'fonte']\n",
    "word_count_year3 = {}\n",
    "\n",
    "for i in keywords_yearNtype:\n",
    "    word_count_year3[i] = {}\n",
    "    for j in keywords_yearNtype[i]:\n",
    "        if j not in word_count_year3[i] and j not in blocked_words:\n",
    "            word_count_year3[i][j] = 1\n",
    "        elif j in word_count_year3[i] and j not in blocked_words:\n",
    "            word_count_year3[i][j] += 1\n",
    "\n",
    "most_used_word_year3 = {}\n",
    "for k in keywords_yearNtype:\n",
    "    word_count_year3[k] = dict(sorted(word_count_year3[k].items(), key=lambda item: item[1], reverse=True))\n",
    "    most_used_word_year3[k] = [list(word_count_year3[k].keys())[0], list(word_count_year3[k].values())[0]/text_quant_yearNtype[k]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86b57ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data5 = {'year': [], 'TCC type': [], 'most used word': [], 'percentage': []}\n",
    "\n",
    "for j in most_used_word_year3:\n",
    "    year_temp = j[:j.find('_')]\n",
    "    type_temp = j[j.find('_')+1:]\n",
    "    data5['year'].append(year_temp)\n",
    "    data5['TCC type'].append(type_temp)\n",
    "    data5['most used word'].append(most_used_word_year3[j][0])\n",
    "    data5['percentage'].append(most_used_word_year3[j][1])\n",
    "    \n",
    "data5['year'].reverse()\n",
    "data5['TCC type'].reverse()\n",
    "data5['most used word'].reverse()\n",
    "data5['percentage'].reverse()\n",
    "\n",
    "palette = ['r']\n",
    "    \n",
    "df = pd.DataFrame(data5)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d13eb9",
   "metadata": {},
   "source": [
    "## Principais palavras de cada ano por tipo de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9254eb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "blocked_words = ['unk', '<', '>']\n",
    "word_count_year3 = {}\n",
    "\n",
    "for i in keywords_yearNtype:\n",
    "    word_count_year3[i] = {}\n",
    "    for j in keywords_yearNtype[i]:\n",
    "        if j not in word_count_year3[i] and j not in blocked_words:\n",
    "            word_count_year3[i][j] = 1\n",
    "        elif j in word_count_year3[i] and j not in blocked_words:\n",
    "            word_count_year3[i][j] += 1\n",
    "\n",
    "most_used_word_year3 = {}\n",
    "for k in keywords_yearNtype:\n",
    "    word_count_year3[k] = dict(sorted(word_count_year3[k].items(), key=lambda item: item[1], reverse=True))\n",
    "    most_used_word_year3[k] = [list(word_count_year3[k].keys())[0], list(word_count_year3[k].values())[0]/text_quant_yearNtype[k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06a78ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data5 = {'year': [], 'TCC type': [], 'most used word': [], 'percentage': []}\n",
    "\n",
    "for j in most_used_word_year3:\n",
    "    year_temp = j[:j.find('_')]\n",
    "    type_temp = j[j.find('_')+1:]\n",
    "    data5['year'].append(year_temp)\n",
    "    data5['TCC type'].append(type_temp)\n",
    "    data5['most used word'].append(most_used_word_year3[j][0])\n",
    "    data5['percentage'].append(most_used_word_year3[j][1])\n",
    "    \n",
    "data5['year'].reverse()\n",
    "data5['TCC type'].reverse()\n",
    "data5['most used word'].reverse()\n",
    "data5['percentage'].reverse()\n",
    "\n",
    "palette = ['r']\n",
    "    \n",
    "df = pd.DataFrame(data5)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6013853",
   "metadata": {},
   "source": [
    "## Uso de determinada palavra ao longo dos anos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259b7e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "choosen_word = 'marketing' #Definir a palavra\n",
    "word_count_year3 = {}\n",
    "data3 = {'year': ['2021','2020','2019','2018','2017','2016'], choosen_word: []}\n",
    "\n",
    "for i in keywords_year:\n",
    "    word_count_year3[i] = {}\n",
    "    for j in keywords_year[i]:\n",
    "        if j not in word_count_year3[i] and j == choosen_word:\n",
    "            word_count_year3[i][j] = 1\n",
    "        elif j in word_count_year3[i] and j == choosen_word:\n",
    "            word_count_year3[i][j] += 1\n",
    "\n",
    "for l in word_count_year3:\n",
    "    try:\n",
    "        data3[choosen_word].append(list(word_count_year3[l].values())[0]/text_quant_year[l])\n",
    "    except IndexError:\n",
    "        data3[choosen_word].append(0)\n",
    "    \n",
    "data3['year'].reverse()\n",
    "data3[choosen_word].reverse()\n",
    "\n",
    "data_preproc = pd.DataFrame(data3)\n",
    "fig = sns.lineplot(x='year', y='value', hue='variable', \n",
    "             data=pd.melt(data_preproc, ['year']), marker=\"o\")\n",
    "\n",
    "fig.set(xlabel='Ano', ylabel='Percentual', ylim=(0, 1))\n",
    "print(data3[choosen_word])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fece184",
   "metadata": {},
   "source": [
    "## ProporÃ§Ã£o de trabalhos em lingua nÃ£o portuguesa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1798b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_pt = {'2021': 0, '2020': 5, '2019': 1, '2018': 0, '2017': 1, '2016': 3}\n",
    "data7 = {'year': ['2021','2020','2019','2018','2017','2016'], 'TCCs em lingua estrangeira': []}\n",
    "\n",
    "for i in text_quant_year:\n",
    "    data7['TCCs em lingua estrangeira'].append(non_pt[i]/(non_pt[i]+text_quant_year[i]))\n",
    "    \n",
    "    \n",
    "data7['year'].reverse()\n",
    "data7['TCCs em lingua estrangeira'].reverse()\n",
    "\n",
    "data_preproc = pd.DataFrame(data7)\n",
    "fig = sns.lineplot(x='year', y='value', hue='variable', \n",
    "             data=pd.melt(data_preproc, ['year']), marker=\"o\")\n",
    "\n",
    "fig.set(xlabel='Ano', ylabel='Percentual', ylim=(0, 1))\n",
    "print(data7['TCCs em lingua estrangeira'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
